<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Transcribe File, Comparing Realtime/TimingStream Options - Watson Speech to Text</title>

  <style type="text/css">
    .row {
      display: flex;
    }
    .column {
      flex: 1; /* stretch to ful width, divide the space evenly */
      margin: 0 10px;
    }
  </style>
  <link rel="stylesheet" href="style.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
</head>
<body>
<div class="container">
<a href="/">&laquo; Examples</a>

<section>
    <h2>Transcribe File, Comparing <code>{realtime: false}</code> to <code>{realtime: true, emitAt: TimingStream.END}</code> and <code>{realtime: true, emitAt: TimingStream.START}</code>  </h2>
    <button id="button">Transcribe and Play</button> <button id="stop">Stop</button>
    <p>When transcription results are available faster than real-time (such as when simultaneously uploading and playing a file on a high-bandwidth connection), the TimingStream slows them down results to real-time. Otherwise it emits them as fast as they arrive.</p>
    <p>Notes:</p>
    <ul>
      <li>A longer, well-compressed file will help make the realtime difference between more apparent.</li>
      <li>The raw RecognizeStream continues displaying new data received from the server and thus does not immediately stop when the Stop button is clicked.</li>
      <li>Supported types are wav, ogg, webm, and flac. (Playback also requires browser support; we recommend ogg/opus or webm/opus for most cases.)</li>
    </ul>

  <!-- two rows so that the contents are always given equal space -->

    <div class="row">
      <div class="column">
        <h2><code>{realtime: false}</code></h2>
      </div>

      <div class="column">
        <h2><code>{realtime: true, emitAt: START}</code></h2>
      </div>

      <div class="column">
        <h2><code>{realtime: true, emitAt: END}</code></h2>
      </div>
    </div>

    <div class="row">
      <div class="column">
        <div id="output">--</div>
      </div>

      <div class="column">
        <div id="realtime-start-output">--</div>
      </div>

      <div class="column">
        <div id="realtime-end-output">--</div>
      </div>
    </div>


</section>

<script src="scripts/watson-speech/dist/watson-speech.js"></script>
<!-- window.fetch pollyfill for IE/Edge & Older Chrome/FireFox -->
<script src="scripts/fetch/dist/fetch.umd.js"></script>

<h2>Code for this demo:</h2>
<pre><code><script style="display: block;">
var stream;
var realtimeStartStream;
var realtimeEndStream;

function renderStream(stream, outputElement) {
  stream.pipe(new WatsonSpeech.SpeechToText.WritableElementStream({
    outputElement: outputElement,
    objectMode: true
  })).on('error', function(err) {
    console.log(err);
  });
}

document.querySelector('#button').onclick = function () {
  fetch('/api/speech-to-text/token').then(function(response) {
    return response.json();
  }).then(function (token) {

    stream = WatsonSpeech.SpeechToText.recognizeFile(Object.assign(token, {
      file: 'Isac_Newton_spoken_Wikipedia_opus.ogg',
      play: true,
      objectMode: true,
      realtime: false, // defaults to true when play is true, but we're going to turn it off and then manually do it in a moment to show the difference
      timestamps: true // defaults to true when realtime is true
      ,format: false
    }));

    stream.on('error', function(err) {
      console.log(err);
    });

    renderStream(stream, '#output');

    // now do what the realtime option would have done: pipe through a TimingStream
    realtimeStartStream = stream.pipe(new WatsonSpeech.SpeechToText.TimingStream({
      highWaterMark: 1000, // this demo only - prevents backpressure from slowing down the source stream - you should leave this set to the default value for regular usage
      objectMode: true,
      emitAt: WatsonSpeech.SpeechToText.TimingStream.START
    }));
    renderStream(realtimeStartStream, '#realtime-start-output');


    // and, again with emitAt set to END (the default value)
    realtimeEndStream = stream.pipe(new WatsonSpeech.SpeechToText.TimingStream({
      highWaterMark: 1000, // this demo only - prevents backpressure from slowing down the source stream - you should leave this set to the default value for regular usage
      objectMode: true,
      emitAt: WatsonSpeech.SpeechToText.TimingStream.END // default
    }));
    renderStream(realtimeEndStream, '#realtime-end-output');

  }).catch(function(error) {
    console.log(error);
  });
};

document.querySelector('#stop').onclick = function() {
  if (stream) {
    stream.stop();
    realtimeStartStream.stop();
    realtimeEndStream.stop();
  }
};
</script></code></pre>
</div>
</body>
</html>
